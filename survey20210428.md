# 1. 调研

- [x] 假设 1 是否合理
- [ ] 评价标准是否合理

# 2. 问题一

> 了解半监督学习和聚类的假设

**参考论文**：[A survey on semi-supervised learning-Jesper E. van Engelen.2020](https://link.springer.com/article/10.1007/s10994-019-05855-6)，《machine learning》

## 2.1. 半监督学习

半监督学习的一个必要条件是：输入空间上的边缘分布$p(x)$包含后验分布$p(y|x)$的信息。否则无法提高预测的准确性。[Zhu.2008](http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf)

### 2.1.1. 平滑性假设

两个输入数据点$x,x'\in X$在输入空间上相邻，相应的标签$y,y'$应该相同。  
在半监督学习中，该假设可以传递地应用与未标签数据。

### 2.1.2. 低密度假设

分类器的决策边界最好通过输入空间中的低密度区域。本质上意味着决策边界应该位于数据点少的区域。决策边界穿过低密度区域（该区域没有任何一对相似数据点），不会违反平滑性假设。因此低密度假设与平滑性假设密切相关。

### 2.1.3. 流形假设

1. 输入空间上的所有数据点由多个低纬流形组成。
2. 位于同一个流形上的数据点具有相同的标签。

## 2.2. 聚类

### 2.2.1. 聚类假设

> 文中认为聚类假设是其他假设的一个概括

**同一簇的数据点属于同一类**——[Chapelle et al.2006](http://www.acad.bg/ebook/ml/MITPress-%20SemiSupervised%20Learning.pdf)  
输入空间$\mathcal{X}$以及数据集$X\subset \mathcal{X}$。一个簇是一个数据点集合$C\subseteq \mathcal{X}$，其相似度高于其他数据点。聚类相当于找一个函数$f:X\rightarrow \mathcal{Y}$，将每个数据点$x\in X$映射到一个聚类标签$y=f(x)$。  
相似性的概念唯一地定义了$p(x)和p(y|x)$的相互作用。因此可以从两个点彼此之间以及与其他点的相似性得出两个点是否属于同一聚类。
聚类假设对应于半监督学习的必要条件：$p(x)$包含有关$p(y|x)$的信息。

## 2.3. 总结

聚类假设涵盖了半监督学习的假设，用其作为假设 1 是合理的。

# 3. 问题二

> v-measure 是聚类评价标准，查找是否有半监督聚类的评价标准。（无监督聚类算法与半监督聚类算法）
> 了解半监督中的聚类如何利用少量标签数据优化无监督聚类或利用无标签数据优化预测性能。

## 3.1. 半监督聚类

**参考论文**：[半监督聚类综述-丁世飞.2019](https://xueshu.baidu.com/usercenter/paper/show?paperid=1c1h0ph0pq3e0ra0fp3p0er0dp076074&site=xueshu_se)，《计算机科学》

> 在聚类和半监督学习的基础上，半监督聚类利用少量标记信息进行数据预处理，改进了传统聚类，得到了更好的结果
> 半监督聚类的评价标准十分重要

### 3.1.1. 基于约束的半监督聚类

> 这类算法的思想特点是在传统聚类的基础上加入约束限制信息来使聚类效果达到最佳。

- COP-Kmeans 算法：[Wagstaff.et](https://www.aaai.org/Papers/AAAI/2000/AAAI00-180.pdf)将成对约束的思想运用到传统 K-means 算法中。在数据分配过程中要求数据对象必须满足 Must-link(ML)和 Cannot-link(CL)约束，并且约束具有**对称性**和**传递性**。

- 改进的 LCop-Kmeans 算法：此算法主要解决了 CL 约束造成违反的问题。

- Seeded-Kmeans 算法：[Basu.et](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.7.9416)基于 Seeds 集改进思想提出的算法。该算法主要目的是将标记样本（可以是少量）引入 K-means 中，将其作为 Seeds 集，同时采用最大期望算法将样本划分为 K 个簇。

- 改进的 SC-Kmeans 算法：Seeded-Kmeans 算法的一种改进。

### 3.1.2. 基于距离的半监督聚类

> 这类算法的特点是在对数据进行预处理的过程中，对样本之间的相似性度量进行变换，从而得到一个新的测量函数，使得相关联的正约束样本之间更加相近而负样本则更加相反

略

## 3.2. 半监督评价指标

### 3.2.1. 近三年相关论文

#### 3.2.1.1. [An Adaptive Robust Semi-Supervised Clustering Framework Using Weighted Consensus of Random k-Means Ensemble-2021](https://www.computer.org/csdl/journal/tk/5555/01/08896034/1eS9AOex0AM)

> IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING(2 区)

评价指标：NMI

#### 3.2.1.2. [Pairwise-constraints based Semi-supervised Fuzzy Clustering with Entropy Regularization-2020](https://ieeexplore.ieee.org/document/9131336)

> 2020 3rd International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)

评价指标：RI

#### 3.2.1.3. [Semi-Supervised Clustering with Neural Networks-2020](https://ieeexplore.ieee.org/document/9232516)

> 2020 IEEE Sixth International Conference on Multimedia Big Data (BigMM)

评价指标：NMI

#### 3.2.1.4. [Safe Semi-Supervised Fuzzy C-Means Clustering-2019](https://ieeexplore.ieee.org/document/8764532)

> IEEE Access(3 区)

评价指标：无

#### 3.2.1.5. [Semi-supervised Clustering by Seeding-2002](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.7.9416)

**Seeding**：
给定一个数据集$\mathcal{X}$，KMeans 簇生成一个 K-partitioning：$\{\mathcal{X}_{l}\}^{K}_{l=1}$，令$S\subseteq \mathcal{X}$（称 seed 集），用户为 seed 集提供相应的$\mathcal{X}_l$簇。假设$\mathcal{X}_l$至少有一个 seed 数据点，因此得到一个 K-partitioning：$\{\mathcal{S}_{l}\}^{K}_{l=1}$，用来指导 KMeans 算法。

**评价指标**：MI

### 3.2.2. 归一化互信息（NMI）

#### 3.2.2.1. 互信息

$$MI(C,K)=I(C;K)$$

- $I(C;K)=H(C)-H(C|K)$
- $C$ 类
- $K$ 簇
- $H(.)$ 熵

**性质**：

1. 对称性：$I(C;K)=I(K;C)$
2. X 与 Y 独立时：$I(C;K)=0$
3. $I(C;K)>=0$
4. 如果$U\rightarrow X\rightarrow Y\rightarrow V$，则$I(U;V)\leq I(X;Y)$

#### 3.2.2.2. 归一化互信息

$$
NMI(C,K)=\frac {2\times I(C;K)}{H(C) + H(K)}
$$

## 3.3. 总结

半监督聚类算法所用评价指基本还是聚类的常用评价指标。

### 3.3.1. 关键问题

> 半监督聚类算法通常利用标签数据优化无监督聚类效果，如基于 k-means 的半监督聚类算法。基于熵的聚类评价标准无法描述聚类结果的标签数据。

$H(C_1)=-\frac {1}{9}{}*\log{\frac{1}{9}} - \frac{8}{9}*\log{\frac{8}{9}}$  
$H(C_2)=-\frac{1}{2}*\log{\frac{1}{2}}-\frac{1}{2}*\log{\frac{1}{2}}=1$

$H(C_1)\leq H(C_2)$

# 4. 半监督学习模型

## 4.1. 假设

**假设 1**：
同一簇的数据点属于同一类

## 4.2. 定义

**定义 1**：半监督聚类-基于 seeding 定义
一个数据集$\mathcal{X}$有$N$个数据点，其类别集合$C=\{c_{i}|i=1,...,n\}$。标签数据集$L$,其类别集合$S=\{s_{i}|i=1,...,m\}$以及簇集合$K=\{k_{i}|i=1,...,m\}$。也就是说每个簇至少有一个$x_i \in L$。

**定义 2**：数据集误差-评价标准
$$Err(\mathcal{X})=\mathcal{D}\{x_{ij}\in \mathcal{X}|c_i\neq k_j\}=1-\sum_{i=1}^{|K|}P(K=i)P(C=i|K=i)$$

**定义 3**：学习模型的序关系
$\forall h_1,h_2\in \mathcal{H}$，如果$Err_1(\mathcal{X})\ge Err_2(\mathcal{X})$，则$h_1 \sqsubseteq h_2$

**定义 4**：数据集的序关系
$\forall \mathcal{X_1},\mathcal{X_2}$，如果$|C_1| \leq|C_2|$，则$\mathcal{X_1}\sqsubseteq \mathcal{X_2}$

## 4.3. 定理

- [ ] **定理 1**：如果$L_1\sqsubseteq L_2$，则$h_1 \sqsubseteq h_2$
